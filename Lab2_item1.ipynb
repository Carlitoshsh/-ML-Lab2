{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_item1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Carlitoshsh/-ML-Lab2/blob/master/Lab2_item1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "up0Ms9FaQ_d8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Class example**\n",
        "\n",
        "Multinomial Naive *Bayes* "
      ]
    },
    {
      "metadata": {
        "id": "45qIXvPwBDUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_probability(nOfSearchWord,totalWords,vocabulary):\n",
        "  probability = (nOfSearchWord + 1)/(totalWords+vocabulary)\n",
        "  return probability"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zhm8zPogJPTk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# In training set\n",
        "pChina = 0.75\n",
        "pNoChina = 0.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scaFA_BQHJZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2d3a2cc4-fe44-486c-903c-6e28ffc148fc"
      },
      "cell_type": "code",
      "source": [
        "pChineseInChina = calculate_probability(5,8,6)\n",
        "pTokyoOrJapanInChina = calculate_probability(0,8,6)\n",
        "pChineseInNoChina = calculate_probability(1,3,6)\n",
        "pTokyoOrJapanInNoChina = calculate_probability(1,3,6)\n",
        "\n",
        "print(\"Chinese|c\",pChineseInChina)\n",
        "print(\"Tokyo|c == Japan|c\",pTokyoOrJapanInChina)\n",
        "print(\"Chinese|¬c\",pChineseInNoChina)\n",
        "print(\"Tokyo|¬c == Japan|¬c\",pTokyoOrJapanInNoChina)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chinese|c 0.42857142857142855\n",
            "Tokyo|c == Japan|c 0.07142857142857142\n",
            "Chinese|¬c 0.2222222222222222\n",
            "Tokyo|¬c == Japan|¬c 0.2222222222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_uOaDN0EHqEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "23d52e43-69c8-459f-8865-3fa3d39d2614"
      },
      "cell_type": "code",
      "source": [
        "# multiply p of China in total, p of each word on test set\n",
        "pChinaOnTestSet = pChina*pow(pChineseInChina,3)*pTokyoOrJapanInChina*pTokyoOrJapanInChina\n",
        "pNoChinaOnTestSet = pNoChina*pow(pChineseInNoChina,3)*pTokyoOrJapanInNoChina*pTokyoOrJapanInNoChina\n",
        "print(pChinaOnTestSet)\n",
        "print(pNoChinaOnTestSet)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00030121377997263036\n",
            "0.00013548070246744223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Wwctvc4TqTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Table](https://cdn1.imggmi.com/uploads/2018/9/24/38544adfc6a83826d864aa121b7073e0-full.png)\n",
        "\n",
        "From [IR book](https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-text-classification-1.html#tab:nbtoyex):\n",
        "\n",
        "Based on the data in Table 13.10 , (i) estimate a multinomial Naive Bayes classifier, (ii) apply the classifier to the test document, (iii) estimate a Bernoulli NB classifier, (iv) apply the classifier to the test document. You need not estimate parameters that you don't need for classifying the test document.\n"
      ]
    },
    {
      "metadata": {
        "id": "Wm4d_cD6aBno",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Using Multinomial Naive Bayes**"
      ]
    },
    {
      "metadata": {
        "id": "73ljzJVsROiT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Over the training set\n",
        "pChinaTS = 0.5\n",
        "pNoChinaTS = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "St-OH5xaT6JY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "6e496fb0-f321-45e3-a892-abfdf6d21448"
      },
      "cell_type": "code",
      "source": [
        "pTaiwanInCTS = calculate_probability(2,5,7)\n",
        "pSapporoInCTS = calculate_probability(0,5,7)\n",
        "pTaiwanInNoCTS = calculate_probability(1,5,7)\n",
        "pSapporoInNoCTS = calculate_probability(2,5,7)\n",
        "\n",
        "print(\"Taiwan|c\",pTaiwanInCTS)\n",
        "print(\"Sapporo|c\",pSapporoInCTS)\n",
        "print(\"Taiwan|¬c\",pTaiwanInNoCTS)\n",
        "print(\"Sapporo|¬c\",pSapporoInNoCTS)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taiwan|c 0.25\n",
            "Sapporo|c 0.08333333333333333\n",
            "Taiwan|¬c 0.16666666666666666\n",
            "Sapporo|¬c 0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JKKnh_iBVFDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e0dd9b84-a338-43ea-bddd-7ff162377301"
      },
      "cell_type": "code",
      "source": [
        "pChinaOnTest = pChinaTS*pow(pTaiwanInCTS,2)*pSapporoInCTS\n",
        "pNoChinaOnTest = pNoChinaTS*pow(pTaiwanInNoCTS,2)*pSapporoInNoCTS\n",
        "\n",
        "print(\"c|docId5\",pChinaOnTest)\n",
        "print(\"¬c|docId5\",pNoChinaOnTest)\n",
        "\n",
        "if(pChinaOnTest >= pNoChinaOnTest):\n",
        "    print(\"\\nDocument is a part of Class China\")\n",
        "else:\n",
        "    print(\"\\nDocument in ¬c\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c|docId5 0.0026041666666666665\n",
            "¬c|docId5 0.003472222222222222\n",
            "Document in ¬c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F_jWpwNPa0-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Using Bernoulli NB**"
      ]
    },
    {
      "metadata": {
        "id": "90LNXazUa8m4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "number_of_cases = 2\n",
        "documents_in_c = 2\n",
        "documents_in_no_c = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_1x4yAOajko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ef9b55fb-ac0f-444f-b3ce-ff60fa9e053f"
      },
      "cell_type": "code",
      "source": [
        "# Obtain each probability according to number of cases and documents in their class\n",
        "pTaiwan_C = calculate_probability(2,documents_in_c,number_of_cases)\n",
        "pSapporo_Osaka_Japan_C = calculate_probability(0,documents_in_c,number_of_cases)\n",
        "pTaipei_Macao_Shangai_C = calculate_probability(1,documents_in_c,number_of_cases)\n",
        "pSapporo_NoC = calculate_probability(2,documents_in_no_c,number_of_cases)\n",
        "pTaiwan_Osaka_Japan_NoC  = calculate_probability(1,documents_in_no_c,number_of_cases)\n",
        "pTaipei_Macao_Shangai_NoC = calculate_probability(0,documents_in_no_c,number_of_cases)\n",
        "\n",
        "# Final prediction\n",
        "pChina_F = pChinaTS*pTaiwan_C*pSapporo_Osaka_Japan_C*pow(1-pSapporo_Osaka_Japan_C,2)*pow(pTaipei_Macao_Shangai_C,3)\n",
        "pNoChina_F = pNoChinaTS*pSapporo_NoC*pTaiwan_Osaka_Japan_NoC*pow(pTaiwan_Osaka_Japan_NoC,2)*pow(1-pTaipei_Macao_Shangai_NoC,3)\n",
        "\n",
        "print(\"c|docId5\",pChina_F)\n",
        "print(\"¬c|docId5\",pNoChina_F)\n",
        "\n",
        "if(pChina_F >= pNoChina_F):\n",
        "    print(\"\\nDocument is a part of Class China\")\n",
        "else:\n",
        "    print(\"\\nDocument in ¬c\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5 0.75 0.5 0.25 0.421875\n",
            "c|docId5 0.006591796875\n",
            "¬c|docId5 0.019775390625\n",
            "Document in ¬c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bnwnZ5-zLlPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}