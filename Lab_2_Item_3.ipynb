{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2 Item 3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Carlitoshsh/-ML-Lab2/blob/master/Lab_2_Item_3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jZHwBpu1V1DR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Lab2\n",
        "##Item 3\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sTZgb8JQV1DU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TE6U3dpPV1Db",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a88f4147-9837-4370-c765-6c7b311b0862"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_table('/content/gdrive/My Drive/Colab Notebooks/TableLab2.txt',  \n",
        "                   sep=':', \n",
        "                   header=None,\n",
        "                   names=['c = China?','words in document'])\n",
        "# label spam as 1, not spam as 0\n",
        "df['c = China?'] = df['c = China?'].replace([\"no\",\"yes\"],[0,1])\n",
        "data = df.values\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 'Chinese Beijing Chinese']\n",
            " [1 'Chinese Chinese Shanghai']\n",
            " [1 'Chinese Macao']\n",
            " [0 'Tokyo Japan Chinese']\n",
            " [1 'Taipei Taiwan']\n",
            " [1 'Macao Taiwan Shanghai']\n",
            " [0 'Japan Sapporo']\n",
            " [0 'Sapporo Osaka Taiwan']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GYpL3P-sV1Df",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ngrams_bayes():\n",
        "    \n",
        "    def __init__(self, data, n=2, split=0.75):\n",
        "        \n",
        "        # split into training and testing data\n",
        "        self.train_data, self.test_data = train_test_split(data,\n",
        "                                                          train_size=split)\n",
        "        # convert into n grams\n",
        "        self.train_data = [[item[0], self.ngrams(n, item[1])] for item in self.train_data]\n",
        "        self.test_data = [[item[0], self.ngrams(n, item[1])] for item in self.test_data]\n",
        "        \n",
        "        # count unique n grams in training data\n",
        "        flattened = [gram for message in self.train_data for gram in message[1]]\n",
        "        self.unique = len(set(flattened))\n",
        "        \n",
        "        # init dicts\n",
        "        self.trainPositive = {}\n",
        "        self.trainNegative = {}\n",
        "        # counters\n",
        "        self.posGramCount = 0\n",
        "        self.negGramCount = 0\n",
        "        self.spamCount = 0\n",
        "        # priors\n",
        "        self.pA = 0\n",
        "        self.pNotA = 0\n",
        "        \n",
        "    def ngrams(self, n, text):\n",
        "        text = text.split(' ')\n",
        "        grams = []\n",
        "        for i in range(len(text)-n+1):\n",
        "            gram = ' '.join(text[i:i+n])\n",
        "            grams.append(gram)\n",
        "        return grams \n",
        "    \n",
        "    def train(self):\n",
        "        \n",
        "        for item in self.train_data:\n",
        "            label = item[0]\n",
        "            grams = item[1]\n",
        "            if label == 1:\n",
        "                self.spamCount += 1   \n",
        "            for gram in grams:\n",
        "                if label == 1:\n",
        "                    self.trainPositive[gram] = self.trainPositive.get(gram, 0) + 1\n",
        "                    self.posGramCount += 1\n",
        "                else:\n",
        "                    self.trainNegative[gram] = self.trainNegative.get(gram, 0) + 1\n",
        "                    self.negGramCount += 1\n",
        "                    \n",
        "        self.pA = self.spamCount/float(len(self.train_data))\n",
        "        self.pNotA = 1.0 - self.pA\n",
        "        \n",
        "    def classify(self, text, alpha=1.0):\n",
        "        \n",
        "        self.alpha = alpha\n",
        "        isSpam = self.pA * self.conditionalText(text, 1)\n",
        "        notSpam = self.pNotA * self.conditionalText(text, 0)\n",
        "        if (isSpam > notSpam):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "    def conditionalText(self, grams, label):\n",
        "        result = 1.0\n",
        "        for ngram in grams:\n",
        "            result *= self.conditionalNgram(ngram, label)\n",
        "        return result\n",
        "    \n",
        "    def conditionalNgram(self, ngram, label):\n",
        "        alpha = self.alpha\n",
        "        if label == 1:\n",
        "            return ((self.trainPositive.get(ngram,0)+alpha) /\n",
        "                    float(self.posGramCount+alpha*self.unique))\n",
        "        else:\n",
        "            return ((self.trainNegative.get(ngram,0)+alpha) /\n",
        "                    float(self.negGramCount+alpha*self.unique))\n",
        "            \n",
        "    def evaluate_test_data(self):\n",
        "        results = []\n",
        "        for test in self.test_data:\n",
        "            label = test[0]\n",
        "            text = test[1]\n",
        "            ruling = self.classify(text)\n",
        "            if ruling == label:\n",
        "                results.append(1) \n",
        "            else:\n",
        "                results.append(0) \n",
        "                \n",
        "        print(\"Evaluated {} test cases. {:.2f}% Accuracy\".format(len(results), 100.0*sum(results)/float(len(results))))\n",
        "        return sum(results)/float(len(results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GqFldvdlV1Dj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0494e461-da4f-42a7-d586-7b1a2fc9c09e"
      },
      "cell_type": "code",
      "source": [
        "unigram_bayes = ngrams_bayes(data,1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ikqAqnVV1Do",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unigram_bayes.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "viULbfKZV1Ds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c878ad6b-0f8f-45b0-9717-3819ff4ee047"
      },
      "cell_type": "code",
      "source": [
        "unigram_bayes.evaluate_test_data()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated 2 test cases. 50.00% Accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "WCWDQg8BcSae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "6951901e-b600-4cd2-ad29-3d7c547cbbbc"
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for _ in range(10):\n",
        "    unigram = ngrams_bayes(data, 1, 0.9)\n",
        "    unigram.train()\n",
        "    results.append(unigram.evaluate_test_data())\n",
        "    \n",
        "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Average Accuracy: 0.60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kB80tBa1V1Dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ff672363-3eeb-42f6-fdbd-c8bae216d307"
      },
      "cell_type": "code",
      "source": [
        "bigram_sms= ngrams_bayes(data,2) \n",
        "bigram_sms.train()\n",
        "bigram_sms.evaluate_test_data()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated 2 test cases. 50.00% Accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "wwmLeWLlclJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "87e05a5d-c798-4a22-f179-43cdd4e922ab"
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for _ in range(10):\n",
        "    bigram_net = ngrams_bayes(data, 2, 0.9)\n",
        "    bigram_net.train()\n",
        "    results.append(bigram_net.evaluate_test_data())\n",
        "    \n",
        "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Average Accuracy: 0.40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1VO0mo9pV1D4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2ffa3b80-1446-4f1e-9b0b-2973d19a4269"
      },
      "cell_type": "code",
      "source": [
        "trigram_sms = ngrams_bayes(data,3) \n",
        "trigram_sms.train()\n",
        "trigram_sms.evaluate_test_data()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated 2 test cases. 50.00% Accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "UBxLAQtSct72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c0b53dfc-0597-4909-d7e1-71536aba21ab"
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for _ in range(10):\n",
        "    trigram_net = ngrams_bayes(data, 3, 0.9)\n",
        "    trigram_net.train()\n",
        "    results.append(trigram_net.evaluate_test_data())\n",
        "    \n",
        "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 100.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Evaluated 1 test cases. 0.00% Accuracy\n",
            "Average Accuracy: 0.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "I-1vYL-GbtbQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#2pac and Biggie"
      ]
    },
    {
      "metadata": {
        "id": "KxkyqD-rV1D_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url_data_biggie = \"https://raw.githubusercontent.com/NoahLidell/math-of-intelligence/master/probability_theory/2pac_lyrics.csv\"\n",
        "biggie_df = pd.read_csv(url_data_biggie, usecols=[1], encoding='latin-1', header=None)\n",
        "biggie_df.columns = [\"lyrics\"]\n",
        "biggie_df[\"lyrics\"] = biggie_df[\"lyrics\"].str.replace('[^\\w\\s]','')\n",
        "biggie_df[\"lyrics\"] = biggie_df[\"lyrics\"].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "380Dmx0PV1ED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "828b0617-a34d-4570-ae3b-c23dbc2d1d3c"
      },
      "cell_type": "code",
      "source": [
        "biggie_df.tail()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i aint got no motherfucking friends\\nthats why...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>troublesome nigga\\nhahaha troublesome 19mother...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>change shit\\ni guess change is good for any of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>i see no changes wake up in the morning and i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>out on bail fresh out of jail california dream...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               lyrics\n",
              "11  i aint got no motherfucking friends\\nthats why...\n",
              "12  troublesome nigga\\nhahaha troublesome 19mother...\n",
              "13  change shit\\ni guess change is good for any of...\n",
              "14  i see no changes wake up in the morning and i ...\n",
              "15  out on bail fresh out of jail california dream..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "q0PJ8oEJV1EJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url_data_pac = \"https://raw.githubusercontent.com/NoahLidell/math-of-intelligence/master/probability_theory/2pac_lyrics.csv\"\n",
        "pac_df = pd.read_csv(url_data_pac, usecols=[1], encoding='latin-1', header=None)\n",
        "pac_df.columns = [\"lyrics\"]\n",
        "pac_df[\"lyrics\"] = pac_df[\"lyrics\"].str.replace('[^\\w\\s]','')\n",
        "pac_df[\"lyrics\"] = pac_df[\"lyrics\"].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4mEuaeQV1EQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c241faa6-36e5-4b79-81c4-803929775314"
      },
      "cell_type": "code",
      "source": [
        "pac_df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>little something for my godson elijah\\nand a l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yo mo bee mayn drop that shit\\nyou know what t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rest in peace to my motherfucker biggy smallz\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>makaveli in this killuminati\\nall through your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>its just me against the world\\nnothin to lose\\...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              lyrics\n",
              "0  little something for my godson elijah\\nand a l...\n",
              "1  yo mo bee mayn drop that shit\\nyou know what t...\n",
              "2  rest in peace to my motherfucker biggy smallz\\...\n",
              "3  makaveli in this killuminati\\nall through your...\n",
              "4  its just me against the world\\nnothin to lose\\..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "jsp8i86iV1EW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "biggie_lyrics = biggie_df[\"lyrics\"].values\n",
        "biggie_lyrics = [ song.split('\\n') for song in biggie_lyrics]\n",
        "biggie_lyrics = [line for song in biggie_lyrics for line in song]\n",
        "pac_lyrics = pac_df[\"lyrics\"].values\n",
        "pac_lyrics = [ song.split('\\n') for song in pac_lyrics]\n",
        "pac_lyrics = [line for song in pac_lyrics for line in song]\n",
        "\n",
        "rap_lines = [] \n",
        "\n",
        "for line in biggie_lyrics:\n",
        "    if len(line.split()) > 3:\n",
        "        rap_lines.append(np.array([0,str(line)]))\n",
        "        \n",
        "for line in pac_lyrics:\n",
        "    if len(line.split()) > 3:\n",
        "        rap_lines.append(np.array([1,str(line)]))\n",
        "        \n",
        "rap_lines = np.array(rap_lines)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zRT2FVaNV1Ea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rap_lines = pd.DataFrame(rap_lines)\n",
        "rap_lines.columns = [\"label\",\"line\"]\n",
        "rap_lines.head()\n",
        "rap_lines['label'] = rap_lines['label'].replace(['0','1'],[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLIRhn6RV1Ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5045e575-a003-4eda-dfd6-ea97f6589be4"
      },
      "cell_type": "code",
      "source": [
        "bayes_biggie_vs_pac = ngrams_bayes(rap_lines.values, 1, 0.9)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dJWmBPiCV1Eo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bayes_biggie_vs_pac.train() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15uSs0H5V1Er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07c7b2f0-58bf-4fbf-e342-a8a80799adba"
      },
      "cell_type": "code",
      "source": [
        "bayes_biggie_vs_pac.evaluate_test_data()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated 221 test cases. 9.50% Accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09502262443438914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "coVz0sfeV1Ez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we have a small data set, let's run multiple trials with different train-test splits to get a better idea of what our average classification accuracy using this method."
      ]
    },
    {
      "metadata": {
        "id": "RXdLucIhV1E0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c9826d11-8fbe-4240-9bf3-c1b9ccb95e13"
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for _ in range(10):\n",
        "    unigram = ngrams_bayes(rap_lines.values, 1, 0.9)\n",
        "    unigram.train()\n",
        "    results.append(unigram.evaluate_test_data())\n",
        "    \n",
        "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluated 221 test cases. 9.05% Accuracy\n",
            "Evaluated 221 test cases. 5.43% Accuracy\n",
            "Evaluated 221 test cases. 4.98% Accuracy\n",
            "Evaluated 221 test cases. 6.79% Accuracy\n",
            "Evaluated 221 test cases. 7.69% Accuracy\n",
            "Evaluated 221 test cases. 9.50% Accuracy\n",
            "Evaluated 221 test cases. 9.50% Accuracy\n",
            "Evaluated 221 test cases. 5.88% Accuracy\n",
            "Evaluated 221 test cases. 9.05% Accuracy\n",
            "Evaluated 221 test cases. 10.41% Accuracy\n",
            "Average Accuracy: 0.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YzTzmy6xV1E5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "not bad, but how do bigram and trigram compare?\n",
        "\n",
        "##### Bigram"
      ]
    },
    {
      "metadata": {
        "id": "sl8xitbRV1E8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c196ebbb-0ee2-4519-c112-dd5bb43f0d8c"
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for _ in range(10):\n",
        "    bigram_net = ngrams_bayes(rap_lines.values, 2, 0.9)\n",
        "    bigram_net.train()\n",
        "    results.append(bigram_net.evaluate_test_data())\n",
        "    \n",
        "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluated 221 test cases. 6.33% Accuracy\n",
            "Evaluated 221 test cases. 5.43% Accuracy\n",
            "Evaluated 221 test cases. 8.14% Accuracy\n",
            "Evaluated 221 test cases. 5.88% Accuracy\n",
            "Evaluated 221 test cases. 6.79% Accuracy\n",
            "Evaluated 221 test cases. 4.98% Accuracy\n",
            "Evaluated 221 test cases. 9.05% Accuracy\n",
            "Evaluated 221 test cases. 6.79% Accuracy\n",
            "Evaluated 221 test cases. 8.14% Accuracy\n",
            "Evaluated 221 test cases. 4.07% Accuracy\n",
            "Average Accuracy: 0.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "laTOgQinV1FB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Trigram"
      ]
    },
    {
      "metadata": {
        "id": "c2PC3NFGV1FC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "00bb109e-0fd9-44f3-d82f-fe578cf11cd7"
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for _ in range(10):\n",
        "    trigram_net = ngrams_bayes(rap_lines.values, 3, 0.9)\n",
        "    trigram_net.train()\n",
        "    results.append(trigram_net.evaluate_test_data())\n",
        "    \n",
        "print(\"Average Accuracy: {:.2f}\".format(sum(results)/float(len(results))))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluated 221 test cases. 9.50% Accuracy\n",
            "Evaluated 221 test cases. 6.33% Accuracy\n",
            "Evaluated 221 test cases. 5.43% Accuracy\n",
            "Evaluated 221 test cases. 5.88% Accuracy\n",
            "Evaluated 221 test cases. 5.43% Accuracy\n",
            "Evaluated 221 test cases. 4.52% Accuracy\n",
            "Evaluated 221 test cases. 4.98% Accuracy\n",
            "Evaluated 221 test cases. 6.79% Accuracy\n",
            "Evaluated 221 test cases. 5.88% Accuracy\n",
            "Evaluated 221 test cases. 6.33% Accuracy\n",
            "Average Accuracy: 0.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J0jEvm10V1FF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Unigrams seem to have a slight edge on bigrams and trigrams but using trigrams doesn't yeild horrible results on this rap data like it did when classing sms messages. My guess is that, while these raps contain highly colloquial words, there are phrases unique to Biggie and Pac that they use repeatedly while with sms messages the sequence of words is more arbitrary. "
      ]
    }
  ]
}