{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2 Item 4,5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Carlitoshsh/-ML-Lab2/blob/master/Lab_2_Item_4,5.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "knssJXXRwW9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### SPAM Detection - The Naive Bayes Algorithm in Python with Scikit-Learn \n",
        "D. Shahrokhian\n",
        "https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "## Item 4\n",
        "Shahrokian has better performance for cities training set that Lidell\n",
        "\n",
        "## Item 5\n",
        "Bernoulli has better performance depending on test_size than Multinomial.  "
      ]
    },
    {
      "metadata": {
        "id": "968r3_HgO66g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a7af201-dd9e-4497-9575-0616691a05c2"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HZ740eawwW9I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cdf93baf-9962-4d23-9ac1-62cb52d2066f"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# SMS Spam Collection Data Set\n",
        "# https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
        "# For first time, you can connect Google Drive with Colaboratory\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "df = pd.read_table('/content/gdrive/My Drive/Colab Notebooks/TableLab2.txt',  \n",
        "                   sep=':', \n",
        "                   header=None,\n",
        "                   names=['c = China?', 'words in document'])\n",
        "df.head()\n",
        "#df['words in document']"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c = China?</th>\n",
              "      <th>words in document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes</td>\n",
              "      <td>Chinese Beijing Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes</td>\n",
              "      <td>Chinese Chinese Shanghai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yes</td>\n",
              "      <td>Chinese Macao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no</td>\n",
              "      <td>Tokyo Japan Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes</td>\n",
              "      <td>Taipei Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  c = China?         words in document\n",
              "0        yes   Chinese Beijing Chinese\n",
              "1        yes  Chinese Chinese Shanghai\n",
              "2        yes             Chinese Macao\n",
              "3         no       Tokyo Japan Chinese\n",
              "4        yes             Taipei Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "MHvyYqjrwW9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b21974eb-bc11-4198-dc0b-24c75fee747e"
      },
      "cell_type": "code",
      "source": [
        "df['c = China?'] = df['c = China?'].map({'no': 0, 'yes': 1})\n",
        "df['words in document'] = df['words in document'].map(lambda x: x.lower())\n",
        "df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c = China?</th>\n",
              "      <th>words in document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>chinese beijing chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>chinese chinese shanghai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>chinese macao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tokyo japan chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>taipei taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   c = China?         words in document\n",
              "0           1   chinese beijing chinese\n",
              "1           1  chinese chinese shanghai\n",
              "2           1             chinese macao\n",
              "3           0       tokyo japan chinese\n",
              "4           1             taipei taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "RR9Db3X7wW9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "904aa51a-9a0d-4df1-b510-7fb3257aaef3"
      },
      "cell_type": "code",
      "source": [
        "# Convert a collection of text documents to a matrix of token counts\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
        "# to allow one letter words count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\") \n",
        "counts = count_vect.fit_transform(df['words in document'])  \n",
        "print counts"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 0)\t1\n",
            "  (0, 1)\t2\n",
            "  (1, 6)\t1\n",
            "  (1, 1)\t2\n",
            "  (2, 3)\t1\n",
            "  (2, 1)\t1\n",
            "  (3, 2)\t1\n",
            "  (3, 9)\t1\n",
            "  (3, 1)\t1\n",
            "  (4, 8)\t1\n",
            "  (4, 7)\t1\n",
            "  (5, 8)\t1\n",
            "  (5, 3)\t1\n",
            "  (5, 6)\t1\n",
            "  (6, 5)\t1\n",
            "  (6, 2)\t1\n",
            "  (7, 4)\t1\n",
            "  (7, 5)\t1\n",
            "  (7, 8)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tN2MTf5JwW9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36b00365-4d0b-4303-991c-e6f8a9899e71"
      },
      "cell_type": "code",
      "source": [
        "counts.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "74ilTl2HwW9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fc193f37-a94e-415c-af13-d6e5bd7e8075"
      },
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(counts, df['c = China?'], test_size=0.1, random_state=69) \n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB().fit(X_train, y_train)  \n",
        "\n",
        "import numpy as np\n",
        "predicted = model.predict(X_test)\n",
        "print(np.mean(predicted == y_test))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, predicted))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "[[0 0]\n",
            " [1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3aVZcUv3wW-A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def performance_test(my_size, my_count, columnLyrics):\n",
        "  per = 0\n",
        "  for i in range(0,10):\n",
        "      X_train, X_test, y_train, y_test = train_test_split(my_count, columnLyrics, test_size=my_size) \n",
        "      model = MultinomialNB().fit(X_train, y_train) \n",
        "\n",
        "      import numpy as np\n",
        "      predicted = model.predict(X_test)\n",
        "      print(np.mean(predicted == y_test))\n",
        "      per += np.mean(predicted == y_test)\n",
        "\n",
        "      from sklearn.metrics import confusion_matrix\n",
        "      print(confusion_matrix(y_test, predicted))\n",
        "\n",
        "  print \"average performance\"\n",
        "  print per/10.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjedVuxZwW-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "c967b3e9-4da3-4ad6-9468-31b33fedf232"
      },
      "cell_type": "code",
      "source": [
        "performance_test(0.1,counts, df['c = China?'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "0.0\n",
            "[[0 1]\n",
            " [0 0]]\n",
            "0.0\n",
            "[[0 0]\n",
            " [1 0]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "0.0\n",
            "[[0 1]\n",
            " [0 0]]\n",
            "0.0\n",
            "[[0 1]\n",
            " [0 0]]\n",
            "1.0\n",
            "[[1]]\n",
            "average performance\n",
            "0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xu6CppJUwW-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "3835c49b-1f4e-4b19-916c-e482f0baf62a"
      },
      "cell_type": "code",
      "source": [
        "performance_test(0.2,counts, df['c = China?'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "1.0\n",
            "[[1 0]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 0]\n",
            " [1 1]]\n",
            "1.0\n",
            "[[1 0]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 0]\n",
            " [1 1]]\n",
            "0.5\n",
            "[[0 0]\n",
            " [1 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "average performance\n",
            "0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aXoR0K-4Zg1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "b1fe8b02-fa04-46ee-d71b-6eeb9c0ed5b7"
      },
      "cell_type": "code",
      "source": [
        "performance_test(0.5,counts, df['c = China?'])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.75\n",
            "[[1 0]\n",
            " [1 2]]\n",
            "0.5\n",
            "[[1 0]\n",
            " [2 1]]\n",
            "0.25\n",
            "[[0 1]\n",
            " [2 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [1 2]]\n",
            "0.5\n",
            "[[0 2]\n",
            " [0 2]]\n",
            "0.75\n",
            "[[1 1]\n",
            " [0 2]]\n",
            "0.75\n",
            "[[1 0]\n",
            " [1 2]]\n",
            "0.75\n",
            "[[1 1]\n",
            " [0 2]]\n",
            "0.75\n",
            "[[1 0]\n",
            " [1 2]]\n",
            "1.0\n",
            "[[1 0]\n",
            " [0 3]]\n",
            "average performance\n",
            "0.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Ue4ZkdeZoNf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Bernoulli**"
      ]
    },
    {
      "metadata": {
        "id": "10Irg2dpZudm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "def performance_test_Bernoulli(my_size, my_count, columnLyrics):\n",
        "  per = 0\n",
        "  for i in range(0,10):\n",
        "      X_train, X_test, y_train, y_test = train_test_split(my_count, columnLyrics, test_size=my_size) \n",
        "      model = BernoulliNB().fit(X_train, y_train) \n",
        "\n",
        "      import numpy as np\n",
        "      predicted = model.predict(X_test)\n",
        "      print(np.mean(predicted == y_test))\n",
        "      per += np.mean(predicted == y_test)\n",
        "\n",
        "      from sklearn.metrics import confusion_matrix\n",
        "      print(confusion_matrix(y_test, predicted))\n",
        "\n",
        "  print \"average performance Bernoulli\"\n",
        "  print per/10.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3jwFW4rQaGZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cb40a51b-560e-4f37-abe8-65723209345c"
      },
      "cell_type": "code",
      "source": [
        "performance_test_Bernoulli(0.1,counts, df['c = China?'])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "1.0\n",
            "[[1]]\n",
            "average performance Bernoulli\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DsVKkjDxaP6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "8eb4dae8-9495-44f8-d4b8-c872a4950e87"
      },
      "cell_type": "code",
      "source": [
        "performance_test_Bernoulli(0.2,counts, df['c = China?'])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "1.0\n",
            "[[2]]\n",
            "1.0\n",
            "[[2]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "1.0\n",
            "[[1 0]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "1.0\n",
            "[[1 0]\n",
            " [0 1]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "average performance Bernoulli\n",
            "0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cyDj04hiaR2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "b5b7ca80-e7fb-4437-9b40-b1fd2736af60"
      },
      "cell_type": "code",
      "source": [
        "performance_test_Bernoulli(0.5,counts, df['c = China?'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.75\n",
            "[[0 0]\n",
            " [1 3]]\n",
            "1.0\n",
            "[[1 0]\n",
            " [0 3]]\n",
            "0.75\n",
            "[[1 1]\n",
            " [0 2]]\n",
            "0.5\n",
            "[[0 1]\n",
            " [1 2]]\n",
            "1.0\n",
            "[[1 0]\n",
            " [0 3]]\n",
            "0.75\n",
            "[[1 1]\n",
            " [0 2]]\n",
            "0.5\n",
            "[[0 2]\n",
            " [0 2]]\n",
            "0.75\n",
            "[[0 1]\n",
            " [0 3]]\n",
            "0.5\n",
            "[[0 2]\n",
            " [0 2]]\n",
            "0.25\n",
            "[[0 3]\n",
            " [0 1]]\n",
            "average performance Bernoulli\n",
            "0.675\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}