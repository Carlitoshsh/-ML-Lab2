\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\title{Machine learning - Lab2}
\author{Carlos Alfonso Gómez Hernández}
\date{October 8, 2018}

\begin{document}

\maketitle

\section{Lab 2.1}

{Based on the table \ref{table:13.10}: }

\begin{table}[h]
\begin{center}
\begin{tabular}{@{}llll@{}}
	\hline
             & docID & words in document     & in c = China? \\ \hline
training set & 1     & Taipei Taiwan         & yes           \\
             & 2     & Macao Taiwan Shanghai & yes           \\
             & 3     & Japan Sapporo         & no            \\
             & 4     & Sapporo Osaka Taiwan  & no            \\
test set     & 5     & Taiwan Taiwan Sapporo & ?             \\
\hline
\end{tabular}
\caption{Data for parameter estimation exercise}
\label{table:13.10}
\end{center}
\end{table}


\subsection{Estimation - Multinomial Naive Bayes classifier}

Probability of class (China, not China) in training set

$$\hat{P}(c) = \frac{1}{2} = 0.5$$
$$\hat{P}(\overline{c}) = \frac{1}{2} = 0.5$$

Probability of each word in test set depending of class

Vocabulary has 7 words. Each class have 5 terms.

\[\hat{P}(Taiwan|c) = \frac{1}{4} = 0.25\]

\[\hat{P}(Sapporo|c) = \frac{1}{12} = 0.0833333...\]

\[\hat{P}(Taiwan|\overline{c}) = \frac{1}{6} = 0.1666666...\]

\[\hat{P}(Sapporo|\overline{c})  = \frac{1}{4} = 0.25\]




\subsection{Applying the classifier to the test document}

Using formula

\[\hat{P}(c|doc5) = \frac{1}{2} * (\frac{1}{4})^2 * \frac{1}{12} \approx 0.0026041666666666665\]
\[\hat{P}(\overline{c}|doc5)  = \frac{1}{2} * (\frac{1}{6})^2 * \frac{1}{4} \approx 0.003472222222222222\]

Document in $\overline{c}$

\subsection{Estimation - Bernoulli NB classifier}
Probability of each word in test set depending of class

There is two classes (China or not China). Each class have 2 documents.

\[\hat{P}(Taiwan|c) = \frac{3}{4} = 0.75\]

\[\hat{P}(Sapporo|c) = \hat{P}(Osaka|c) = \hat{P}(Japan|c) = \frac{1}{4} = 0.25\]

\[\hat{P}(Taipei|c) = \hat{P}(Macao|c) = \hat{P}(Shanghai|c) = \frac{1}{2} = 0.5\]

\[\hat{P}(Sapporo|\overline{c}) = \frac{3}{4} = 0.75\]

\[\hat{P}(Taiwan|\overline{c}) = \hat{P}(Osaka|\overline{c}) = \hat{P}(Japan|\overline{c}) = \frac{1}{2} = 0.5\]

\[\hat{P}(Taipei|\overline{c}) = \hat{P}(Macao|\overline{c}) = \hat{P}(Shanghai|\overline{c}) = \frac{1}{4} = 0.25\]


\subsection{Applying the classifier to the test document}

Using formula and previous values calculated

\begin{equation}
    \begin{aligned}
\hat{P}(c|doc5) = {} & \hat{P}(c) * \hat{P}(Taiwan|c) *  \hat{P}(Sapporo|c) * (1 - \hat{P}(Osaka|c) ) * (1-\hat{P}(Japan|c) ) \\
& * (1 - \hat{P}(Shanghai|c) ) * (1-\hat{P}(Macao|c) ) * (1 - \hat{P}(Taipei|c) ) \\ & \approx 0.006591796875
 \end{aligned}
\end{equation}

\begin{equation}
    \begin{aligned}
\hat{P}(\overline{c}|doc5) = {} & \hat{P}(\overline{c}) * \hat{P}(Taiwan|\overline{c}) *  \hat{P}(Sapporo|\overline{c}) * (1 - \hat{P}(Osaka|\overline{c}) ) * (1-\hat{P}(Japan|\overline{c}) ) \\
& * (1 - \hat{P}(Shanghai|\overline{c}) ) * (1-\hat{P}(Macao|\overline{c}) ) * (1 - \hat{P}(Taipei|\overline{c}) ) \\ 
& \approx 0.019775390625
 \end{aligned}
\end{equation}

Document in $\overline{c}$

\section{Algorithm}

To modify time complexity of ApplyMultinomialNB, I call a function named SelectDistinctTokens (line 3). This receives has parameter the list of tokens extrated from each document. Then, the conditional probability is only calculated one time for each token (line 6). 

\makeatletter
    \def\BState{\State\hskip-\ALG@thistlm}
    \makeatother
    %this changes the style of the comments 

    \begin{algorithm}
        \caption{Apply Multinomial NB}\label{euclid}
        \algblockdefx[Foreach]{Foreach}{EndForeach}[1]{\textbf{foreach} #1 \textbf{do}}{\textbf{end foreach}}
        
        \begin{algorithmic}[1]
            \Procedure{ApplyMultinomialNB}{$C, V, prior, condprob, d$}    
            \State$W\gets ExtractTokensFromDoc(V,d)$
            \State$D\gets SelectDistinctTokens(W)$
				\Foreach{$c \in C$}
					\State $score[c]\gets log prior[c]$
					\Foreach {$d \in D$}
						\State $score[c] += log condprob[d][c]$
					\EndForeach
				\EndForeach
            \State \textbf{return} $arg max_{e \in C}score[c]$\Comment{Naive Bayes algorithm}
            \EndProcedure
        \end{algorithmic}
    \end{algorithm}

\end{document}
